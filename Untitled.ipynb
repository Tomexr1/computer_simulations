{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de142c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import scipy.integrate as integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d95398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3bab45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACORN(N, k=9, M=2**89-1, Lag=10000):\n",
    "    # N - number of samples\n",
    "    # k - number of bits\n",
    "    # M - modulus\n",
    "    # Lag - lag\n",
    "    # returns: list of N samples\n",
    "    seed = np.random.randint(1, 2**30)\n",
    "    Xs = np.zeros((k+1, N+Lag))\n",
    "    Xs[0, :] = seed\n",
    "    for m in range(1, k+1):\n",
    "        for n in range(1, N+Lag):\n",
    "            Xs[m, n] = (Xs[m-1, n] + Xs[m, n-1]) % M\n",
    "    return Xs[k, Lag:] / M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "Xs = ACORN(N)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(np.arange(10000, N+10000, 1), Xs, s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "Xs = ACORN(N)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Xs[:-1], Xs[1:], s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b132e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 100000\n",
    "Xs = ACORN(N)\n",
    "fig, ax = plt.subplots()\n",
    "sns.histplot(Xs, stat='density', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ffb208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "Ns = np.arange(100, 10000, 100)\n",
    "acorn_times, numpy_times = [], []\n",
    "for n in Ns:\n",
    "    start = time.time()\n",
    "    ACORN(n)\n",
    "    acorn_times.append(time.time() - start)\n",
    "    start = time.time()\n",
    "    np.random.rand(n)\n",
    "    numpy_times.append(time.time() - start)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Ns, acorn_times, label='ACORN', s=1)\n",
    "ax.scatter(Ns, numpy_times, label='numpy', s=1)\n",
    "ax.set_xlabel('n')\n",
    "ax.set_ylabel('time')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52cf407",
   "metadata": {},
   "source": [
    "# Zad 2  Generowanie rozkładu normalnego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef31bd",
   "metadata": {},
   "source": [
    "## Implementacje z laboratoriów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78cc32f",
   "metadata": {},
   "source": [
    "Podczas laboratoriów zaimplementowaliśmy generowanie rozkładu normalnego przy użyciu trzech metod: metody odwrotnej dystrybuanty, biorąc za przybliżenie funkcji odwrotnej funkcję $scipy.stats.norm.ppf$; metody Boxa-Muellera; metody biegunowej. Poniżej widzimy impelementacje tych generatorów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd0c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_inv_cdf(size, mu=0, sigma=1):\n",
    "    \"\"\"\n",
    "    Generuje n liczb z rozkładu normalnego o parametrach mu i sigma przy pomocy metody odwrotnej dystrybuanty.\n",
    "\n",
    "    :param n: (int) liczba liczb do wygenerowania\n",
    "    :param mu: (float) wartość oczekiwana\n",
    "    :param sigma: (float) odchylenie standardowe\n",
    "    :return: (np.ndarray) n liczb z rozkładu normalnego\n",
    "    \"\"\"\n",
    "    \n",
    "    us = stats.uniform.rvs(size=size)\n",
    "    return stats.norm.ppf(us, loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e74c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_muller(size=1, mu=0, sigma=1):\n",
    "    \"\"\"\n",
    "    Generuje n liczb z rozkładu normalnego o parametrach mu i sigma za pomocą metody Boxa-Muellera\n",
    "\n",
    "    :param n: (int) liczba liczb do wygenerowania\n",
    "    :param mu: (float) wartość oczekiwana\n",
    "    :param sigma: (float) odchylenie standardowe\n",
    "    :return: (np.ndarray) n liczb z rozkładu normalnego\n",
    "    \"\"\"\n",
    "    \n",
    "    u1, u2 = np.random.uniform(size=int(np.ceil(size / 2))), np.random.uniform(\n",
    "        size=int(np.ceil(size / 2))\n",
    "    )\n",
    "    Xs = np.sqrt(-2 * np.log(u1)) * np.cos(2 * np.pi * u2) * sigma + mu\n",
    "    Ys = np.sqrt(-2 * np.log(u1)) * np.sin(2 * np.pi * u2) * sigma + mu\n",
    "    return np.hstack((Xs, Ys))[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c8c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polar_method(size=1, mu=0, sigma=1):\n",
    "    \"\"\"\n",
    "    Generuje n liczb z rozkładu normalnego o parametrach mu i sigma za pomocą metody biegunowej\n",
    "    \n",
    "    :param n: (int) liczba liczb do wygenerowania\n",
    "    :param mu: (float) wartość oczekiwana\n",
    "    :param sigma: (float) odchylenie standardowe\n",
    "    :return: (np.ndarray) n liczb z rozkładu normalnego\n",
    "    \"\"\"\n",
    "    \n",
    "    Zs = []\n",
    "    while True:\n",
    "        us = np.array(\n",
    "            [\n",
    "                np.random.uniform(-1, 1, size=int(np.ceil(0.6 * (size - len(Zs))))),\n",
    "                np.random.uniform(-1, 1, size=int(np.ceil(0.6 * (size - len(Zs))))),\n",
    "            ]\n",
    "        )  # expected value powtórzeń ~ 1.2\n",
    "        R_sq = np.sum(us**2, axis=0)\n",
    "        us = np.vstack((us, R_sq))\n",
    "        xs = np.where(\n",
    "            us[2] <= 1, np.sqrt(-2 * np.log(us[2]) / us[2]) * us[0] * sigma + mu, 0\n",
    "        )\n",
    "        xs = xs[xs != 0]\n",
    "        ys = np.where(\n",
    "            us[2] <= 1, np.sqrt(-2 * np.log(us[2]) / us[2]) * us[1] * sigma + mu, 0\n",
    "        )\n",
    "        ys = ys[ys != 0]\n",
    "        Zs = np.hstack((Zs, xs, ys))\n",
    "        if len(Zs) >= size:\n",
    "            break\n",
    "    return Zs[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c72b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polar_method(size=1, mu=0, sigma=1):\n",
    "    \"\"\"\n",
    "    Generuje n liczb z rozkładu normalnego o parametrach mu i sigma za pomocą metody biegunowej\n",
    "    \n",
    "    :param n: (int) liczba liczb do wygenerowania\n",
    "    :param mu: (float) wartość oczekiwana\n",
    "    :param sigma: (float) odchylenie standardowe\n",
    "    :return: (np.ndarray) n liczb z rozkładu normalnego\n",
    "    \"\"\"\n",
    "    \n",
    "    p = np.pi/4\n",
    "    aux = p*(1-p)\n",
    "    x = (3*np.sqrt(aux) + np.sqrt(9*aux + p*size))/p\n",
    "    N = np.ceil(x*x)\n",
    "\n",
    "    V1 = np.random.uniform(-1,1,size)\n",
    "    V2 = np.random.uniform(-1,1,size)\n",
    "    R2 = V1*V1 + V2*V2\n",
    "\n",
    "    index = R2<1\n",
    "\n",
    "    V1 = V1[index][:size]\n",
    "    V2 = V2[index][:size]\n",
    "    R2 = R2[index][:size]\n",
    "    X = V1 * np.sqrt(-2*np.divide(np.log(R2), R2))\n",
    "    Y = V2 * np.sqrt(-2*np.divide(np.log(R2), R2))\n",
    "    return np.concatenate((X, Y))[:size] * sigma + mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebc5cf",
   "metadata": {},
   "source": [
    "Aby sprawdzić poprawność powyższych metod, dla każdej z nich wykonamy wykresy porównujące unormowany histogram z teoretyczną gęstością, empiryczną dystrybuantę z teoretyczną dystrybuantą oraz wykresy kwantylowe. Porównamy również próbkowe esytmatory wartości oczekiwanej oraz wariancji z wartościami teoretycznymi. Dla każdego generatora przyjmujemy wartość oczekiwaną mu=1, odchylenie standardowe sigma=2 oraz ilość próbek n=10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47115bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma, n = 1, 2, 10000\n",
    "X = np.zeros(shape=(3, n))\n",
    "X[0, :] = norm_inv_cdf(n, mu, sigma)\n",
    "X[1, :] = box_muller(n, mu, sigma)\n",
    "X[2, :] = polar_method(n, mu, sigma)\n",
    "print('----------------------------------- NORMAL INV CDF -----------------------------------')\n",
    "print('Expected value empirical:', np.average(X[0]), 'Expected value Theoretical:', mu)\n",
    "print('Variance empirical:', np.var(X[0]), 'Variance Theoretical:', sigma**2)\n",
    "print('----------------------------------- BOX MULLER -----------------------------------')\n",
    "print('Expected value empirical:', np.average(X[1]), 'Expected value Theoretical:', mu)\n",
    "print('Variance empirical:', np.var(X[1]), 'Variance Theoretical:', sigma**2)\n",
    "print('----------------------------------- POLAR METHOD -----------------------------------')\n",
    "print('Expected value empirical:', np.average(X[2]), 'Expected value Theoretical:', mu)\n",
    "print('Variance empirical:', np.var(X[2]), 'Variance Theoretical:', sigma**2)\n",
    "fig, axes = plt.subplots(3, 3, layout=\"constrained\")\n",
    "fig.set_size_inches(8, 5)\n",
    "val1 = np.unique(X[0, :])\n",
    "val2 = np.unique(X[1, :])\n",
    "val3 = np.unique(X[2, :])\n",
    "axes[0, 0].plot(\n",
    "    val1,\n",
    "    stats.norm.pdf(val1, loc=1, scale=2),\n",
    "    c=\"y\",\n",
    "    label=\"pdf theoretical\",\n",
    ")\n",
    "sns.histplot(\n",
    "    X[0, :], stat=\"density\", ax=axes[0, 0], color=\"red\", alpha=0.5, label=\"pdf empirical\"\n",
    ")\n",
    "axes[1, 0].plot(\n",
    "    val1,\n",
    "    stats.norm.cdf(val1, loc=1, scale=2),\n",
    "    label=\"cdf theoretical\",\n",
    "    linestyle=(0, (5, 10)),\n",
    ")\n",
    "sns.ecdfplot(X[0, :], label=\"cdf empirical\", color=\"red\", alpha=0.5, ax=axes[1, 0])\n",
    "stats.probplot(X[0, :], dist=\"norm\", sparams=(1, 2), plot=axes[2, 0])\n",
    "axes[0, 0].set_title(\"Normal Inv CDF\")\n",
    "axes[0, 1].plot(\n",
    "    val2,\n",
    "    stats.norm.pdf(val2, loc=1, scale=2),\n",
    "    c=\"y\",\n",
    "    label=\"pdf theoretical\",\n",
    ")\n",
    "sns.histplot(\n",
    "    X[1, :], stat=\"density\", ax=axes[0, 1], color=\"red\", alpha=0.5, label=\"pdf empirical\"\n",
    ")\n",
    "axes[1, 1].plot(\n",
    "    val2,\n",
    "    stats.norm.cdf(val2, loc=1, scale=2),\n",
    "    label=\"cdf theoretical\",\n",
    "    linestyle=(0, (5, 10)),\n",
    ")\n",
    "sns.ecdfplot(X[1, :], label=\"cdf empirical\", color=\"red\", alpha=0.5, ax=axes[1, 1])\n",
    "stats.probplot(X[1, :], dist=\"norm\", sparams=(1, 2), plot=axes[2, 1])\n",
    "axes[0, 1].set_title(\"Box Muller\")\n",
    "axes[0, 2].plot(\n",
    "    val3,\n",
    "    stats.norm.pdf(val3, loc=1, scale=2),\n",
    "    c=\"y\",\n",
    "    label=\"pdf theoretical\",\n",
    ")\n",
    "sns.histplot(\n",
    "    X[2, :], stat=\"density\", ax=axes[0, 2], color=\"red\", alpha=0.5, label=\"pdf empirical\"\n",
    ")\n",
    "axes[1, 2].plot(\n",
    "    val3,\n",
    "    stats.norm.cdf(val3, loc=1, scale=2),\n",
    "    label=\"cdf theoretical\",\n",
    "    linestyle=(0, (5, 10)),\n",
    ")\n",
    "sns.ecdfplot(X[2, :], label=\"cdf empirical\", color=\"red\", alpha=0.5, ax=axes[1, 2])\n",
    "stats.probplot(X[2, :], dist=\"norm\", sparams=(1, 2), plot=axes[2, 2])\n",
    "axes[0, 2].set_title(\"Polar Method\")\n",
    "fig.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b71af7",
   "metadata": {},
   "source": [
    "Jak widać na wykresach powyżej, wszystkie trzy metody generacji działają poprawnie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079bd26e",
   "metadata": {},
   "source": [
    "## Dodatkowe metody generacji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ceed5",
   "metadata": {},
   "source": [
    "### Metoda tuzina\n",
    "Polega ona na generowaniu 12 realizacji zmiennych losowych z rozkładu U(0,1), dodaniu ich do siebie i na końcu odjęciu liczby 6. Uzyskana w ten sposób liczba jest w przybliżeniu realizacją zmiennej losowej z rozkładu N(0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5604f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuzin(size, mu=0, sigma=1):\n",
    "    \"\"\"\n",
    "    Generuje n liczb z rozkładu normalnego o parametrach mu i sigma za pomocą metody tuzina\n",
    "\n",
    "    :param size: (int) liczba liczb do wygenerowania\n",
    "    :param mu: (float) wartość oczekiwana\n",
    "    :param sigma: (float) odchylenie standardowe\n",
    "    :return: (np.ndarray) n liczb z rozkładu normalnego\n",
    "    \"\"\"\n",
    "    \n",
    "    Us = np.random.uniform(size=(size, 12))\n",
    "    return sigma * (np.sum(Us, axis=1) - 6) + mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c10197e",
   "metadata": {},
   "source": [
    "Wykonamy teraz taki sam test dla tego generatora jak dla trzech poprzednich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a844256",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma, n = 1, 2, 10000\n",
    "X = tuzin(n, mu, sigma)\n",
    "print('----------------------------------- METODA TUZINA -----------------------------------')\n",
    "print('Expected value empirical:', np.average(X), 'Expected value Theoretical:', mu)\n",
    "print('Variance empirical:', np.var(X), 'Variance Theoretical:', sigma**2)\n",
    "fig, axes = plt.subplots(1, 3, layout=\"constrained\")\n",
    "fig.set_size_inches(8, 3)\n",
    "val = np.unique(X)\n",
    "axes[0].plot(\n",
    "    val,\n",
    "    stats.norm.pdf(val, loc=1, scale=2),\n",
    "    c=\"y\",\n",
    "    label=\"pdf theoretical\",\n",
    ")\n",
    "sns.histplot(\n",
    "    X, stat=\"density\", ax=axes[0], color=\"red\", alpha=0.5, label=\"pdf empirical\"\n",
    ")\n",
    "axes[1].plot(\n",
    "    val,\n",
    "    stats.norm.cdf(val, loc=1, scale=2),\n",
    "    label=\"cdf theoretical\",\n",
    "    linestyle=(0, (5, 10)),\n",
    ")\n",
    "sns.ecdfplot(X, label=\"cdf empirical\", color=\"red\", alpha=0.5, ax=axes[1])\n",
    "stats.probplot(X, dist=\"norm\", sparams=(1, 2), plot=axes[2])\n",
    "fig.suptitle(\"Metoda tuzina\")\n",
    "axes[0].set_title('Gęstość')\n",
    "axes[1].set_title('Dystrybuanta')\n",
    "fig.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4e3b25",
   "metadata": {},
   "source": [
    "### Metoda zigguratu\n",
    "Przed implementacją docelowego algorytmu bierzemy funkcję $f(x) = \\exp(-x^2/2)$, która jest przeskalowaną funkcją gęstości rozkładu N(0,1). Skupiamy się tylko na dziedzinie liczb rzeczywistych dodatnich. Obszar pod wykresem funkcji dzielimy na $n$ prostokątów o równych polach, ustawione jeden nad drugim. Zapełniamy tablicę $n$ wartościami $x$ i odpowiadającymi ich wartościami $f(x)$ zaczynając od ustalonego $x_1$. Wygenerowaną tablicę będziemy wykorzystywać każdorazowo przy generacji zmiennych losowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: np.exp(-x**2 / 2)\n",
    "f_inv = lambda y: np.sqrt(-2 * np.log(y))\n",
    "n = 256\n",
    "x1 = 3.6541528853610088\n",
    "y1 = f(x1)\n",
    "Table = np.zeros(shape=(n, 2))\n",
    "Table[0, 0] = x1\n",
    "Table[0, 1] = y1\n",
    "tail_area = integrate.quad(f, x1, np.inf)[0]\n",
    "A = x1 * y1 + tail_area\n",
    "for i in range(1, n-1):\n",
    "    Table[i, 1] = Table[i-1, 1] + A / Table[i-1, 0]\n",
    "    Table[i, 0] = f_inv(Table[i, 1])\n",
    "Table[n-1, 0] = 0\n",
    "Table[n-1, 1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa929315",
   "metadata": {},
   "source": [
    "W docelowym algorytmie generujemy kandydatów na $x$ z różnych warstw prosotkątów. Jeśli $x$ jest większy od $x_1$ stosujemy alternatywny algorytm. Jeśli jest większy, przy użyciu wygenerowanej tablicy sprawdzamy czy znajduje się on poniżej krzywej. Żeby nie generować tylko zmiennych losowych dodatnich, 50% z nich będzie ujemna, dzięki wybraniu $U_0$ z rozkładu U(-1,1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14324da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ziggurat(size=1, mu=0, sigma=1, counter=False):\n",
    "    \"\"\"\n",
    "    Generuje n liczb z rozkładu normalnego o parametrach mu i sigma za pomocą metody zigguratu\n",
    "\n",
    "    :param size: (int) liczba liczb do wygenerowania\n",
    "    :param mu: (float) wartość oczekiwana\n",
    "    :param sigma: (float) odchylenie standardowe\n",
    "    :param counter: (bool) czy zwracać liczbę razy kiedy trzeba obliczyć eksponentę\n",
    "    :return: (np.ndarray) n liczb z rozkładu normalnego\n",
    "    \"\"\"\n",
    "    \n",
    "    c = 0\n",
    "    Xs = np.zeros(size)\n",
    "    for i in range(size):\n",
    "        while True:\n",
    "            indx = int(np.floor(256 * np.random.uniform() - 1))\n",
    "            U0 = 2 * np.random.uniform() - 1\n",
    "            if i == -1:\n",
    "                x = U0 * A / Table[0, 1]\n",
    "            else:\n",
    "                x = U0 * Table[indx, 0]\n",
    "            if np.abs(x) < Table[indx+1, 0]:\n",
    "                Xs[i] = x\n",
    "                break\n",
    "            if indx == -1:  # fallback\n",
    "                while True:\n",
    "                    x = -np.log(np.random.uniform()) / Table[0, 0]\n",
    "                    y = -np.log(np.random.uniform())\n",
    "                    if 2 * y > x**2:\n",
    "                        Xs[i] = x + Table[0, 0]\n",
    "                        break\n",
    "                break\n",
    "            else:\n",
    "                c += 1\n",
    "                y = Table[indx, 1] + np.random.uniform() * (Table[indx+1, 1] - Table[indx, 1])\n",
    "                if y < f(x):\n",
    "                    Xs[i] = x\n",
    "                    break\n",
    "    if counter:\n",
    "        return c\n",
    "    return Xs * sigma + mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9015edfe",
   "metadata": {},
   "source": [
    "Wykonamy teraz taki sam test dla tego generatora jak dla poprzednich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542773b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma, n = 1, 2, 10000\n",
    "X = ziggurat(n, mu, sigma)\n",
    "print('----------------------------------- METODA ZIGGURATU -----------------------------------')\n",
    "print('Expected value empirical:', np.average(X), 'Expected value Theoretical:', mu)\n",
    "print('Variance empirical:', np.var(X), 'Variance Theoretical:', sigma**2)\n",
    "fig, axes = plt.subplots(1, 3, layout=\"constrained\")\n",
    "fig.set_size_inches(8, 3)\n",
    "val = np.unique(X)\n",
    "axes[0].plot(\n",
    "    val,\n",
    "    stats.norm.pdf(val, loc=1, scale=2),\n",
    "    c=\"y\",\n",
    "    label=\"pdf theoretical\",\n",
    ")\n",
    "sns.histplot(\n",
    "    X, stat=\"density\", ax=axes[0], color=\"red\", alpha=0.5, label=\"pdf empirical\"\n",
    ")\n",
    "axes[1].plot(\n",
    "    val,\n",
    "    stats.norm.cdf(val, loc=1, scale=2),\n",
    "    label=\"cdf theoretical\",\n",
    "    linestyle=(0, (5, 10)),\n",
    ")\n",
    "sns.ecdfplot(X, label=\"cdf empirical\", color=\"red\", alpha=0.5, ax=axes[1])\n",
    "stats.probplot(X, dist=\"norm\", sparams=(1, 2), plot=axes[2])\n",
    "fig.suptitle(\"Metoda zigguratu\")\n",
    "axes[0].set_title('Gęstość')\n",
    "axes[1].set_title('Dystrybuanta')\n",
    "fig.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e0a772",
   "metadata": {},
   "source": [
    "#### Test ilości razy obliczania funkcji wykładniczej\n",
    "W algorytmie, funkcję wykładniczą obliczamy tylko w przypadku gdy wartość bezwzględna kandydata $x$ dla wylosowanego indeksu $i$ jest większa od $x_{i+1}$, czyli $x$ nie mieści się w wylosowanym prostokącie. W tym przypadku sprawdzany jest warunek $y < f(x)$. Sprawdzimy teraz ile średnio razy mamy z nim do czynienia dla próbek rozmiaru $n=1000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03716cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros(1000)\n",
    "for i in range(1000):\n",
    "    counts[i] = ziggurat(1000, counter=True)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8, 3)\n",
    "sns.boxplot(counts, ax=ax)\n",
    "ax.set_title('Liczba przypadków na 1000 generacji')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fce289",
   "metadata": {},
   "source": [
    "Jak widać na wykresie pudełkowym powyżej, przy generacji 1000 zmiennych losowych, średnio ok. 15 razy algorytm wpada w przypadek, w którym trzeba obliczyć eskponentę. W większości przypadków wartość ta nie będzie przekraczać 25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924fa146",
   "metadata": {},
   "source": [
    "### Porównanie efektywności algorytmów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ececa6fa",
   "metadata": {},
   "source": [
    "#### Czas wykonania algorytmu w zależności od wielkości próby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "ns = np.arange(100, 10000, 100)\n",
    "times = np.zeros(shape=(np.size(ns), 5))\n",
    "for i in range(len(ns)):\n",
    "    start = time.time()\n",
    "    norm_inv_cdf(ns[i])\n",
    "    times[i, 0] = time.time() - start\n",
    "    start = time.time()\n",
    "    box_muller(ns[i])\n",
    "    times[i, 1] = time.time() - start\n",
    "    start = time.time()\n",
    "    polar_method(ns[i])\n",
    "    times[i, 2] = time.time() - start\n",
    "    start = time.time()\n",
    "    tuzin(ns[i])\n",
    "    times[i, 3] = time.time() - start\n",
    "    start = time.time()\n",
    "    ziggurat(ns[i])\n",
    "    times[i, 4] = time.time() - start\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, layout=\"constrained\")\n",
    "fig.set_size_inches(10,3)\n",
    "axes[0].plot(ns, times[:, 0], label=\"Normal Inv CDF\")\n",
    "axes[0].plot(ns, times[:, 1], label=\"Box-Muller\")\n",
    "axes[0].plot(ns, times[:, 2], label=\"Polar Method\")\n",
    "axes[0].plot(ns, times[:, 3], label=\"Tuzin\")\n",
    "axes[0].plot(ns, times[:, 4], label=\"Ziggurat\")\n",
    "axes[0].set_title(\"Czas wykonania (z metodą zigguratu)\")\n",
    "axes[0].set_xlabel(\"Ilość próbek n\")\n",
    "axes[0].set_ylabel(\"Czas\")\n",
    "axes[0].legend()\n",
    "axes[1].plot(ns, times[:, 0], label=\"Normal Inv CDF\")\n",
    "axes[1].plot(ns, times[:, 1], label=\"Box-Muller\")\n",
    "axes[1].plot(ns, times[:, 2], label=\"Polar Method\")\n",
    "axes[1].plot(ns, times[:, 3], label=\"Tuzin\")\n",
    "axes[1].set_title(\"Czas wykonania (bez metody zigguratu)\")\n",
    "axes[1].set_xlabel(\"Ilość próbek n\")\n",
    "axes[1].set_ylabel(\"Czas\")\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2d92b",
   "metadata": {},
   "source": [
    "Czas wykonia algorytmu wykorzystującego metodę zigguratu jest znacząco dłuższy od czasów dla pozostałych algorytmów. Jest to spowodoawne faktem, że jako jedyny nie został zaimplementowany wektorowo. Metody biegunowa, odwrotnej dystrybuanty oraz Boxa-Muellera są najszybsze. Czas generowania metodą tuzina lekko odstaje od tych trzech."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f8a426",
   "metadata": {},
   "source": [
    "#### Dokładność symulacji - test Kolomogorova-Smirnova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2640b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_statistic_method1, ks_pvalue_method1 = stats.kstest(norm_inv_cdf, 'norm')\n",
    "ks_statistic_method2, ks_pvalue_method2 = stats.kstest(box_muller, 'norm')\n",
    "ks_statistic_method3, ks_pvalue_method3 = stats.kstest(polar_method, 'norm')\n",
    "ks_statistic_method4, ks_pvalue_method4 = stats.kstest(tuzin, 'norm')\n",
    "ks_statistic_method5, ks_pvalue_method5 = stats.kstest(ziggurat, 'norm')\n",
    "\n",
    "print(f\"Normal Inv CDF K-S Test: statistic={ks_statistic_method1}, p-value={ks_pvalue_method1}\\n\")\n",
    "print(f\"Box-Mueller K-S Test: statistic={ks_statistic_method2}, p-value={ks_pvalue_method2}\\n\")\n",
    "print(f\"Polar Method K-S Test: statistic={ks_statistic_method3}, p-value={ks_pvalue_method3}\\n\")\n",
    "print(f\"Tuzin K-S Test: statistic={ks_statistic_method4}, p-value={ks_pvalue_method4}\\n\")\n",
    "print(f\"Ziggurat K-S Test: statistic={ks_statistic_method5}, p-value={ks_pvalue_method5}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34cac8d",
   "metadata": {},
   "source": [
    "Dla domyślnych 20 realizacji zmiennych losowych przeprowadziliśmy test Kolmogorova-Smirnova przy użyciu funkcji $scipy.stats.kstest$. Statysyka testowa dla każdego z generatorów jest rzędu $10^{-1}$. P-wartości również są na podobnym poziomie. Biorąc pod uwagę poziom istotności testu $\\alpha = 0.05$, nie mamy przesłanek do odrzucenia hipotezy zerowej ($H_0$ - realizacje pochodzą z rozkładu normalnego) dla żadnego z generatorów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa3bb8",
   "metadata": {},
   "source": [
    "# Zad3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6775b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(n):\n",
    "    Xs = np.random.uniform(size=n)\n",
    "    return 4 * np.sum(1 / (1 + Xs ** 2)) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e45d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def antithetic_variates(n):\n",
    "    Xs = np.random.uniform(size=n//2)\n",
    "    Xs = np.concatenate((Xs, 1 - Xs))\n",
    "    return np.sum(4 / (1 + Xs ** 2)) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899cc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_variates(n):\n",
    "    Xs = np.random.uniform(size=n)\n",
    "    f = lambda x: 4 / (1 + x ** 2)\n",
    "    g = lambda x: x\n",
    "    g_mean = np.mean(g(Xs))\n",
    "    f_mean = np.mean(f(Xs))\n",
    "    cov = np.mean((f(Xs) - f_mean) * (g(Xs) - g_mean))\n",
    "    c = -cov / np.var(g(Xs))\n",
    "    print(c)\n",
    "    return f_mean + c * (g_mean - 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc29efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_variates(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28271b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = np.arange(100, 10000, 10)\n",
    "vals = np.zeros(shape=(3,len(ns)))\n",
    "i = 0\n",
    "for n in ns:\n",
    "    vals[0, i] = monte_carlo(n)\n",
    "    vals[1, i] = antithetic_variates(n)\n",
    "    vals[2, i] = control_variates(n)\n",
    "    i += 1\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 6)\n",
    "ax.scatter(ns, vals[0, :] - np.pi, label='Monte Carlo', s=1)\n",
    "ax.scatter(ns, vals[1, :] - np.pi, label='Antithetic Variates', s=1)\n",
    "ax.scatter(ns, vals[2, :] - np.pi, label='Control Variates', s=1)\n",
    "# ax.plot(ns, ns*[np.pi])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106ff7b4",
   "metadata": {},
   "source": [
    "# Zad 6 - prawa arcusa sinusa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ce7de",
   "metadata": {},
   "source": [
    "## Proces Wienera\n",
    "Zaczniemy od implementacji procesu Wienera $W_t$ oraz stworzeniu wykresu przykładowej trajektorii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener_process(n):\n",
    "    \"\"\"\n",
    "    Generuje n liczb z procesu Wienera o parametrach mu i sigma\n",
    "\n",
    "    :param n: (int) liczba liczb do wygenerowania\n",
    "    :param mu: (float) wartość oczekiwana\n",
    "    :param sigma: (float) odchylenie standardowe\n",
    "    :return: (np.ndarray) n liczb z procesu Wienera\n",
    "    \"\"\"\n",
    "    return np.concatenate((np.zeros(1), np.cumsum(norm_inv_cdf(n, 0, 1/n))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.001\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 6)\n",
    "ax.plot(np.arange(0, 1+h, h), wiener_process(1000), label='W_t')\n",
    "ax.set_title('Przykładowa trajektoria realizacji procesu Wienera')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a155d71",
   "metadata": {},
   "source": [
    "## Rozkład arcusa sinusa\n",
    "Niech $X$ będzie zmienną losową z rozkładu arcusa sinusa ($X$ ~ Arcsine). Wtedy jej gęstość wyraża się wzorem \n",
    "\\begin{equation}\n",
    "    f(x) = \\frac{1}{\\pi\\sqrt{x-x^2}}\\mathbb{1}_{(0,1)}(x).\n",
    "\\end{equation}\n",
    "Z kolei dystrybuanta ma postać\n",
    "\\begin{equation}\n",
    "F(x) = \\begin{cases}\n",
    "0, & \\text{gdy } x < 0,\\\\\n",
    "\\frac{2}{\\pi}\\arcsin\\sqrt{x}, & \\text{gdy } x = 0,\\\\\n",
    "1, & \\text{gdy } x < 0.\n",
    "\\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66dc18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_arcsin = lambda x: 1 / (np.pi * np.sqrt(x - x**2))  # gęstość\n",
    "F_arcsin = lambda x: 2 / np.pi * np.arcsin(np.sqrt(x))  # dystrybuanta               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbabcdd",
   "metadata": {},
   "source": [
    "## I prawo arcusa sinusa\n",
    "\\begin{equation}\n",
    " T_+ = \\lambda(\\{t\\in [0,1] | W_t > 0\\}) \\sim \\text{Arcsine},\n",
    "\\end{equation}\n",
    "gdzie $\\lambda$ to miara Lebesgue'a. Czyli długość czasu, w którym proces znajdował się powyżej osi $OX$ ma rozkład arcusa sinusa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d79dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts = np.zeros(10000)\n",
    "for i in range(10000):\n",
    "    Xs = wiener_process(1000)\n",
    "    Xs_pos = Xs[Xs > 0]\n",
    "    Ts[i] = len(Xs_pos) / 1000\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, layout=\"constrained\")\n",
    "fig.set_size_inches(10,3)\n",
    "sns.histplot(Ts, stat='density', color='red', alpha=0.5, ax=axes[0], label='Gęstość empiryczna')\n",
    "sns.lineplot(x=np.unique(Ts), y=f_arcsin(np.unique(Ts)), color='blue', alpha=0.5, ax=axes[0],\n",
    "             label='Gęstość teoretyczna')\n",
    "sns.ecdfplot(Ts, ax=axes[1], color='red', linestyle=':', linewidth=4, label='Dystrybuanta empiryczna')\n",
    "sns.lineplot(x=np.arange(0, 1, 0.001), y=F_arcsin(np.arange(0, 1, 0.001)), ax=axes[1], color='blue',\n",
    "             label='Dystrybuanta teoretyczna', linewidth=2, alpha=0.9)\n",
    "fig.suptitle('Wykresy rozkładu T_+')\n",
    "axes[0].set_title('Gęstość')\n",
    "axes[1].set_title('Dystrybuanta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b8daab",
   "metadata": {},
   "source": [
    "## II prawo arcusa sinusa\n",
    "\\begin{equation}\n",
    " L = \\text{sup}\\{t\\in [0,1] | W_t = 0\\} \\sim \\text{Arcsine},\n",
    "\\end{equation}\n",
    "Czyli moment, w którym proces przecina oś $OX$ ma rozkład arcusa sinusa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts = np.zeros(10000)\n",
    "i = 0\n",
    "while i != 10000:\n",
    "    Xs = wiener_process(1000)\n",
    "    if np.any(Xs > 0) and np.any(Xs < 0):\n",
    "#         j = 1000\n",
    "#         while True:\n",
    "# #         for j in range(1, 1000)[::-1]:\n",
    "#             if Xs[j] * Xs[j-1] < 0:\n",
    "#                 Ts[i] = j / 1000\n",
    "#                 i += 1\n",
    "#                 break\n",
    "#             j -= 1\n",
    "        Xs = Xs[:-1] * Xs[1:]\n",
    "        Ts[i] = np.where(Xs < 0)[0][-1] / len(Xs)\n",
    "        i += 1\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, layout=\"constrained\")\n",
    "fig.set_size_inches(10,3)\n",
    "sns.histplot(Ts, stat='density', color='red', alpha=0.5, ax=axes[0], label='Gęstość empiryczna')\n",
    "sns.lineplot(x=np.unique(Ts), y=f_arcsin(np.unique(Ts)), color='blue', alpha=0.5, ax=axes[0],\n",
    "             label='Gęstość teoretyczna')\n",
    "sns.ecdfplot(Ts, ax=axes[1], color='red', linestyle=':', linewidth=4, label='Dystrybuanta empiryczna')\n",
    "sns.lineplot(x=np.arange(0, 1, 0.001), y=F_arcsin(np.arange(0, 1, 0.001)), ax=axes[1], color='blue',\n",
    "             label='Dystrybuanta teoretyczna', linewidth=2, alpha=0.9)\n",
    "fig.suptitle('Wykresy rozkładu L')\n",
    "axes[0].set_title('Gęstość')\n",
    "axes[1].set_title('Dystrybuanta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1f035",
   "metadata": {},
   "source": [
    "## III prawo arcusa sinusa\n",
    "\\begin{equation}\n",
    " W_M = sup\\{W_t | t\\in [0,1]\\},\n",
    "\\end{equation}\n",
    "wtedy $M$ ~ Arcsine. Czyli moment, w którym proces osiąga maksymalną wartość ma rozkład arcusa sinusa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ee13e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ts = np.zeros(10000)\n",
    "for i in range(10000):\n",
    "    Xs = wiener_process(1000)\n",
    "    Ts[i] = np.argmax(Xs) / 1000\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, layout=\"constrained\")\n",
    "fig.set_size_inches(10,3)\n",
    "sns.histplot(Ts, stat='density', color='red', alpha=0.5, ax=axes[0], label='Gęstość empiryczna')\n",
    "sns.lineplot(x=np.unique(Ts), y=f_arcsin(np.unique(Ts)), color='blue', alpha=0.5, ax=axes[0],\n",
    "             label='Gęstość teoretyczna')\n",
    "sns.ecdfplot(Ts, ax=axes[1], color='red', linestyle=':', linewidth=4, label='Dystrybuanta empiryczna')\n",
    "sns.lineplot(x=np.arange(0, 1, 0.001), y=F_arcsin(np.arange(0, 1, 0.001)), ax=axes[1], color='blue',\n",
    "             label='Dystrybuanta teoretyczna', linewidth=2, alpha=0.9)\n",
    "fig.suptitle('Wykresy rozkładu M')\n",
    "axes[0].set_title('Gęstość')\n",
    "axes[1].set_title('Dystrybuanta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba9a94",
   "metadata": {},
   "source": [
    "Jak widać na wykresach, gęstości i dystrybuanty empiryczne tych trzech zmiennych losowych pokrywają się z gęstością i dystrybuantą rozkładu arcusa sinusa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
